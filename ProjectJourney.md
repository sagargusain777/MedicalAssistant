ğŸ—ºï¸ Project Setup & Backend Foundation â€” Step-by-Step
âœ… Step 1 â€” Initialize the Project with uv

Created a new Python project using:

uv init

This generated the base project structure and dependency system.

âœ… Step 2 â€” Create Virtual Environment

Created and activated a virtual environment using:

uv venv

Ensured dependency isolation and clean package management for the project.

âœ… Step 3 â€” Modify main.py & Add API Route

Updated main.py to:

Initialize the FastAPI application.

Create the first route endpoint for testing or health checks.

This served as the starting backend entry point for the system.

âœ… Step 4 â€” Create config/ Folder

Added a new folder named config.

Purpose: centralize configuration-related logic (database, environment variables, etc.).

âœ… Step 5 â€” Add MongoDB Configuration File

Inside config/, created a database module to:

Load environment variables using python-dotenv.

Read:

MongoDB connection URI.

Database name.

Initialize MongoDB client.

Test connection using ping.

Create database object.

Fetch the users collection for future authentication logic.

ğŸ‘‰ This established the database layer for the project.

âœ… Step 6 â€” Setup MongoDB Cloud Project

Created a MongoDB Atlas account.

Set up a new cloud database project.

Generated:

Database cluster.

Connection URI.

Added credentials to environment variables instead of hard-coding them.

âœ… Step 7 â€” Add .env File

Created a .env file to securely store:

MONGODB_URI

MONGO_DB_NAME

Ensured secrets remain outside version control.

âœ… Step 8 â€” Add requirements.txt

Added initial dependencies:

pymongo â†’ MongoDB driver.

fastapi[standard] â†’ backend framework.

uvicorn â†’ ASGI server for running FastAPI apps.
âœ… Step 9 â€” Create auth/ Module

Added a dedicated auth folder to isolate authentication and authorization logic from the main application.

This follows a modular backend design pattern.

âœ… Step 10 â€” Implement Password Hashing Logic

Created a hashpasswords.py file to handle secure credential storage:

Used bcrypt for cryptographic hashing.

Implemented:

hash_password() â†’ converts plaintext password into a salted hash.

verify_password() â†’ checks login attempts against stored hashes.

Applied:

UTF-8 encoding before hashing.

Decoding hashed output to string for MongoDB storage.

ğŸ‘‰ This ensures:
âœ” Passwords are never stored in plaintext
âœ” Secure authentication practices
âœ” Industry-standard cryptography

âœ… Step 11 â€” Define User Signup Schema

Created a Pydantic model for request validation:

SignUpRequest

username

password

role

This enforces:

Proper request body structure.

Automatic validation by FastAPI.

âœ… Step 12 â€” Create Authentication Routes

Added a routes.py file inside auth/ to expose authentication endpoints.

Implemented:
ğŸ”¹ Signup Endpoint (POST /signup)

Checks if the username already exists.

Hashes the password before storing it.

Inserts user record into MongoDB.

Returns success confirmation.

ğŸ”¹ Login Flow with HTTP Basic Auth

Used FastAPIâ€™s HTTPBasic security dependency.

Created an authenticate() function to:

Fetch user from MongoDB.

Validate password using bcrypt.

Reject invalid users or credentials with HTTP 401.

Added:

GET /login route protected by the authentication dependency.

Returns user role and welcome message on success.

âœ… Step 13 â€” Database Integration for Auth

Connected authentication logic directly to:

users_collection from MongoDB config.

This made the database the single source of truth for users.
âœ… Step 14 â€” Create docs/ Module

Added a new folder named docs to isolate document-processing and retrieval logic.

Purpose: handle PDF ingestion, chunking, embeddings, and vector storage for the RAG pipeline.

âœ… Step 15 â€” Implement Vector Store Pipeline

Inside docs/vectorstores.py, you:

Loaded environment variables for:

Google Generative AI embeddings API key.

Pinecone API key.

Pinecone environment.

Pinecone index name.

Injected API keys into runtime environment for LangChain compatibility.

âœ… Step 16 â€” Setup Upload Directory

Created a server-side folder (./uploads) to persist files uploaded from the frontend.

Used:

os.makedirs(..., exist_ok=True)
to avoid errors if the directory already exists.

ğŸ‘‰ This establishes your document ingestion layer.

âœ… Step 17 â€” Initialize Pinecone Client

Created a Pinecone client using API credentials.

Configured a ServerlessSpec:

Cloud: AWS

Region: us-east-1

This prepares the vector database backend.

âœ… Step 18 â€” Auto-Create Vector Index

Implemented logic to:

List existing Pinecone indexes.

Check whether the target index already exists.

Create the index only if missing with:

Dimension: 768

Metric: dotproduct

Poll Pinecone until the index status becomes READY.

ğŸ‘‰ This makes your system idempotent â€” safe to run multiple times without breaking infra.

âœ… Step 19 â€” Connect to Vector Index

Retrieved a handle to the created Pinecone index object.

This enables:

Inserting embeddings.

Running semantic search queries later.

âœ… Step 20 â€” Implement File-Upload Processing Function

Created:

ğŸ”¹ load_vectorstore(uploaded_files, role: str, doc_id: str)

Inside this function you:

Initialized Google Gemini embedding model:

gemini-embedding-001

Iterated over uploaded files from frontend.

Saved each file to disk inside ./uploads/.

Used Path for OS-safe file paths.

Wrote binary data correctly using "wb" mode.

ğŸ‘‰ This function becomes the entry point for:

âœ” Uploading medical PDFs
âœ” Persisting documents
âœ” Preparing them for chunking + embedding
âœ” Storing them in Pinecone (next step)